{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ceb19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "Embedding(3, 2)\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Random scenario setup\n",
    "B = 1       # batch size\n",
    "z_dim = 5      # latent size\n",
    "K = 3          # number of classes\n",
    "e = 2          # embedding dimension\n",
    "img_dim = 6    # fake image flattened size (toy)\n",
    "\n",
    "# Create random z and labels\n",
    "z = torch.randn(B, z_dim)\n",
    "print(z.shape)\n",
    "\n",
    "y = torch.randint(0, K, (B,))\n",
    "\n",
    "# Embedding for classes\n",
    "embedding = nn.Embedding(K, e)\n",
    "print(embedding)\n",
    "y_emb = embedding(y)\n",
    "print(y_emb.shape)\n",
    "\n",
    "# Generator input\n",
    "g_in = torch.cat([z, y_emb], dim=1)\n",
    "print(g_in.shape)\n",
    "# Fake generator (just linear for demo)\n",
    "G = nn.Linear(z_dim + e, img_dim)\n",
    "x_hat = G(g_in)\n",
    "\n",
    "# Flatten real \"images\" (random)\n",
    "x = torch.randn(B, img_dim)\n",
    "x_flat = x.view(B, -1)\n",
    "\n",
    "# Discriminator input\n",
    "d_in = torch.cat([x_flat, y_emb], dim=1)\n",
    "D = nn.Linear(img_dim + e, 1)\n",
    "score = D(d_in)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f80aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator input: torch.Size([2, 3, 224, 224])\n",
      "Generator output: torch.Size([2, 16, 224, 224])\n",
      "Critic output: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.shs_gan.shs_generator import Generator\n",
    "from src.models.shs_gan.shs_discriminator import Critic3D\n",
    "\n",
    "def test_shapes():\n",
    "    gen = Generator()\n",
    "    critic = Critic3D()\n",
    "    \n",
    "    # Test input\n",
    "    x = torch.randn(2, 3, 224, 224)\n",
    "    print(f\"Generator input: {x.shape}\")\n",
    "    \n",
    "\n",
    "    fake_hsi = gen(x)\n",
    "    print(f\"Generator output: {fake_hsi.shape}\")  # Should be [2, 16, 224, 224]\n",
    "    \n",
    "  \n",
    "    score = critic(fake_hsi)\n",
    "    print(f\"Critic output: {score.shape}\")  # Should be [2, 1]\n",
    "    \n",
    "    return fake_hsi, score\n",
    "\n",
    "fake_hsi, score = test_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5297f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import dependencies\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ebdc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIG FILE ANALYSIS ===\n",
      "Class path: data_modules.HSIDermoscopyDataModule\n",
      "Image size: 256\n",
      "Batch size: 4\n",
      "Allowed labels: ['melanoma']\n",
      "Data directory: data/hsi_dermoscopy\n",
      "\n",
      "=== FIXED TRANSFORMS ===\n",
      "Replaced interpolation variables with actual values\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'class_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m init_args = config[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33minit_args\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     40\u001b[39m init_args[\u001b[33m'\u001b[39m\u001b[33mclass_path\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33msrc.data_modules.HSIDermoscopyDataModule\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m datamodule = \u001b[43mHSIDermoscopyDataModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== DATAMODULE CREATED ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatamodule.hparams.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'class_path'"
     ]
    }
   ],
   "source": [
    "# Test the dataset and configuration only\n",
    "\n",
    "# 1. Load and analyze the config file\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config_path = \"/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/configs/data/hsi_dermoscopy_synth.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=== CONFIG FILE ANALYSIS ===\")\n",
    "print(f\"Class path: {config['data']['class_path']}\")\n",
    "print(f\"Image size: {config['data']['init_args']['image_size']}\")\n",
    "print(f\"Batch size: {config['data']['init_args']['batch_size']}\")\n",
    "print(f\"Allowed labels: {config['data']['init_args']['allowed_labels']}\")\n",
    "print(f\"Data directory: {config['data']['init_args']['data_dir']}\")\n",
    "\n",
    "# 2. Fix the interpolation issues in transforms\n",
    "image_size = config['data']['init_args']['image_size']\n",
    "\n",
    "# Replace the interpolation variables with actual values\n",
    "if 'transforms' in config['data']['init_args']:\n",
    "    transforms = config['data']['init_args']['transforms']\n",
    "    for stage in ['train', 'val', 'test']:\n",
    "        if stage in transforms:\n",
    "            for transform in transforms[stage]:\n",
    "                if 'init_args' in transform:\n",
    "                    for key, value in transform['init_args'].items():\n",
    "                        if isinstance(value, str) and '${data.init_args.image_size}' in value:\n",
    "                            transform['init_args'][key] = image_size\n",
    "\n",
    "print(\"\\n=== FIXED TRANSFORMS ===\")\n",
    "print(\"Replaced interpolation variables with actual values\")\n",
    "\n",
    "# 3. Import and setup the data module\n",
    "from src.data_modules.hsi_dermoscopy import HSIDermoscopyDataModule\n",
    "\n",
    "# Use the fixed config directly instead of OmegaConf\n",
    "init_args = config['data']['init_args']\n",
    "init_args['class_path'] = \"src.data_modules.HSIDermoscopyDataModule\"\n",
    "\n",
    "datamodule = HSIDermoscopyDataModule(**init_args)\n",
    "\n",
    "print(\"\\n=== DATAMODULE CREATED ===\")\n",
    "print(f\"Task: {datamodule.hparams.task}\")\n",
    "print(f\"Image size: {datamodule.hparams.image_size}\")\n",
    "print(f\"Batch size: {datamodule.hparams.batch_size}\")\n",
    "\n",
    "# 4. Prepare data (download if needed)\n",
    "print(\"\\n=== PREPARING DATA ===\")\n",
    "datamodule.prepare_data()\n",
    "\n",
    "# 5. Setup for training\n",
    "print(\"\\n=== SETUP DATA SPLITS ===\")\n",
    "datamodule.setup(stage='fit')\n",
    "\n",
    "# 6. Check dataset sizes\n",
    "print(\"\\n=== DATASET SIZES ===\")\n",
    "print(f\"Training samples: {len(datamodule.data_train)}\")\n",
    "print(f\"Validation samples: {len(datamodule.data_val)}\")\n",
    "if hasattr(datamodule, 'data_test'):\n",
    "    print(f\"Test samples: {len(datamodule.data_test)}\")\n",
    "\n",
    "# 7. Test one batch from training loader\n",
    "print(\"\\n=== TESTING ONE BATCH ===\")\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "if isinstance(batch, (list, tuple)):\n",
    "    images, labels = batch\n",
    "    print(f\"Batch images shape: {images.shape}\")  # [B, C, H, W]\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n",
    "    print(f\"Image dtype: {images.dtype}\")\n",
    "    print(f\"Label dtype: {labels.dtype}\")\n",
    "    print(f\"Image value range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "else:\n",
    "    print(f\"Unexpected batch format: {type(batch)}\")\n",
    "\n",
    "print(\"\\n=== CONFIGURATION TEST COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/main.py fit -c configs/data/hsi_dermoscopy_synth.yaml -c configs/model/shs_gan.yaml\n",
    "d1f0e4f28a2d0dfd6eb977721654e79967e39dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651ea246",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from src.models.shs_gan.shs_generator import Generator\n",
    "from src.models.shs_gan.shs_discriminator import Critic3D\n",
    "from src.data_modules.hsi_dermoscopy import HSIDermoscopyDataModule\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "402df810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data config:\n",
      "data:\n",
      "  class_path: data_modules.HSIDermoscopyDataModule\n",
      "  init_args:\n",
      "    task: GENERATION\n",
      "    train_val_test_split:\n",
      "    - 0.7\n",
      "    - 0.15\n",
      "    - 0.15\n",
      "    image_size: 256\n",
      "    batch_size: 4\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    allowed_labels:\n",
      "    - melanoma\n",
      "    data_dir: data/hsi_dermoscopy\n",
      "    google_drive_id: 1WyIHxY1zh_f3uXwUVRvX9CzuFtfJchmx\n",
      "    balanced_sampling: false\n",
      "    transforms:\n",
      "      train:\n",
      "      - class_path: SmallestMaxSize\n",
      "        init_args:\n",
      "          max_size: ${data.init_args.image_size}\n",
      "      - class_path: CenterCrop\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: Resize\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: ToTensorV2\n",
      "        init_args: {}\n",
      "      val:\n",
      "      - class_path: SmallestMaxSize\n",
      "        init_args:\n",
      "          max_size: ${data.init_args.image_size}\n",
      "      - class_path: CenterCrop\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: Resize\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: ToTensorV2\n",
      "        init_args: {}\n",
      "      test:\n",
      "      - class_path: SmallestMaxSize\n",
      "        init_args:\n",
      "          max_size: ${data.init_args.image_size}\n",
      "      - class_path: CenterCrop\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: Resize\n",
      "        init_args:\n",
      "          height: ${data.init_args.image_size}\n",
      "          width: ${data.init_args.image_size}\n",
      "      - class_path: ToTensorV2\n",
      "        init_args: {}\n",
      "\n",
      "\n",
      "Model config:\n",
      "model:\n",
      "  class_path: modules.SHSGAN\n",
      "  init_args:\n",
      "    in_channels: 1\n",
      "    out_channels: 16\n",
      "    img_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    base_filters: 64\n",
      "    critic_fft_arm: true\n",
      "    lr: 0.0002\n",
      "    betas:\n",
      "    - 0.5\n",
      "    - 0.999\n",
      "    lambda_gp: 10.0\n",
      "    n_critic: 5\n",
      "    num_log_samples: 2\n",
      "    log_channels:\n",
      "    - 0\n",
      "    - 1\n",
      "    - 2\n",
      "trainer:\n",
      "  log_every_n_steps: 10\n",
      "  max_epochs: 10\n",
      "  logger:\n",
      "    class_path: WandbLogger\n",
      "    init_args:\n",
      "      save_dir: logs\n",
      "      entity: k298976-unicamp\n",
      "      project: hypersynth\n",
      "      tags:\n",
      "      - hsi\n",
      "      - gan\n",
      "      - shs-gan\n",
      "      log_model: false\n",
      "  callbacks:\n",
      "  - class_path: ModelCheckpoint\n",
      "    init_args:\n",
      "      filename: epoch={epoch:02d}-g_loss={val/g_loss:.4f}-d_loss={val/d_loss:.4f}\n",
      "      monitor: val/g_loss\n",
      "      verbose: true\n",
      "      save_last: true\n",
      "      mode: min\n",
      "      auto_insert_metric_name: false\n",
      "  - class_path: EarlyStopping\n",
      "    init_args:\n",
      "      monitor: val/g_loss\n",
      "      min_delta: 0.01\n",
      "      patience: 15\n",
      "      verbose: true\n",
      "      mode: min\n",
      "      strict: true\n",
      "  - class_path: LearningRateMonitor\n",
      "    init_args:\n",
      "      logging_interval: step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load YAML configs\n",
    "cfg_data = OmegaConf.load(\"/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/configs/data/hsi_dermoscopy_synth.yaml\")\n",
    "cfg_model = OmegaConf.load(\"/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/configs/model/shs_gan.yaml\")\n",
    "\n",
    "# Print them to verify\n",
    "print(\"Data config:\")\n",
    "print(OmegaConf.to_yaml(cfg_data))\n",
    "\n",
    "print(\"\\nModel config:\")\n",
    "print(OmegaConf.to_yaml(cfg_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a04cad03",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Instantiate datamodule from YAML\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m datamodule = \u001b[43mHSIDermoscopyDataModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcfg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m datamodule.prepare_data()\n\u001b[32m      4\u001b[39m datamodule.setup(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: HSIDermoscopyDataModule.__init__() got an unexpected keyword argument 'data'"
     ]
    }
   ],
   "source": [
    "# Instantiate datamodule from YAML\n",
    "datamodule = HSIDermoscopyDataModule(**cfg_data)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "real_hsi, _ = batch\n",
    "\n",
    "print(f\"Real HSI batch shape: {real_hsi.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715f82ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "One or more data directories do not exist in data/hsi_dermoscopy_croppedv2_256",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- instantiate data module ---\u001b[39;00m\n\u001b[32m     13\u001b[39m data_module = HSIDermoscopyDataModule(\n\u001b[32m     14\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mGENERATION\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     train_val_test_split=(\u001b[32m0.7\u001b[39m, \u001b[32m0.15\u001b[39m, \u001b[32m0.15\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     image_size=\u001b[32m64\u001b[39m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mdata_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m train_loader = data_module.train_dataloader()\n\u001b[32m     23\u001b[39m real_imgs, _ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/src/data_modules/hsi_dermoscopy.py:285\u001b[39m, in \u001b[36mHSIDermoscopyDataModule.setup\u001b[39m\u001b[34m(self, stage)\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[38;5;28mself\u001b[39m.test_indices = np.loadtxt(split_dir / \u001b[33m\"\u001b[39m\u001b[33mtest.txt\u001b[39m\u001b[33m\"\u001b[39m, dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    284\u001b[39m         \u001b[38;5;66;03m# last resort, regenerate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# Use the indices from setup_splits to create the splits\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.data_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/src/data_modules/hsi_dermoscopy.py:182\u001b[39m, in \u001b[36mHSIDermoscopyDataModule.setup_splits\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_splits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    181\u001b[39m     seed = \u001b[32m42\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     full_dataset = \u001b[43mHSIDermoscopyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     indices = np.arange(\u001b[38;5;28mlen\u001b[39m(full_dataset))\n\u001b[32m    185\u001b[39m     labels = full_dataset.labels_df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].map(full_dataset.labels_map).to_numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/src/data_modules/datasets/hsi_dermoscopy_dataset.py:60\u001b[39m, in \u001b[36mHSIDermoscopyDataset.__init__\u001b[39m\u001b[34m(self, task, data_dir, transform)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m.labels_df = pd.read_csv(\u001b[38;5;28mself\u001b[39m.labels_df_path)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28mself\u001b[39m.labels_df = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.labels_df.to_csv(\u001b[38;5;28mself\u001b[39m.labels_df_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.setup_labels_df()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/datahdd/kris_volume/dgm-2025.2/projects/hyperskin/src/data_modules/datasets/hsi_dermoscopy_dataset.py:162\u001b[39m, in \u001b[36mHSIDermoscopyDataset.create_df\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    155\u001b[39m other_lesions_path = images_path / \u001b[33m\"\u001b[39m\u001b[33mOtherCube\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\n\u001b[32m    158\u001b[39m     dysplastic_nevi_path.exists(),\n\u001b[32m    159\u001b[39m     melanoma_path.exists(),\n\u001b[32m    160\u001b[39m     other_lesions_path.exists()\n\u001b[32m    161\u001b[39m ]):\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOne or more data directories do not exist in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.data_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    166\u001b[39m data = []\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lesion_type, path \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    169\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mdysplastic_nevi\u001b[39m\u001b[33m\"\u001b[39m, dysplastic_nevi_path),\n\u001b[32m    170\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mmelanoma\u001b[39m\u001b[33m\"\u001b[39m, melanoma_path)\n\u001b[32m    171\u001b[39m ]:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: One or more data directories do not exist in data/hsi_dermoscopy_croppedv2_256"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.modules.generative.gan.wgan import WGANModule\n",
    "from src.data_modules import HSIDermoscopyDataModule\n",
    "\n",
    "# ---- CONFIG ----\n",
    "ckpt_path = None        # or path to a trained checkpoint if you want to load weights\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- instantiate data module ---\n",
    "data_module = HSIDermoscopyDataModule(\n",
    "    task=\"GENERATION\",\n",
    "    train_val_test_split=(0.7, 0.15, 0.15),\n",
    "    batch_size=4,\n",
    "    data_dir=\"data/hsi_dermoscopy_croppedv2_256\",\n",
    "    image_size=64,\n",
    ")\n",
    "data_module.setup(\"fit\")\n",
    "\n",
    "train_loader = data_module.train_dataloader()\n",
    "real_imgs, _ = next(iter(train_loader))\n",
    "real_imgs = real_imgs.to(device)\n",
    "\n",
    "# --- instantiate model ---\n",
    "model = WGANModule(\n",
    "    img_channels=16,\n",
    "    input_channels=1,\n",
    "    img_size=64,\n",
    "    constraint_method=\"gp\",  # or \"clip\"\n",
    ")\n",
    "if ckpt_path:\n",
    "    model = model.load_from_checkpoint(ckpt_path)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- generate fake images ---\n",
    "z = torch.randn_like(real_imgs[:, :model.hparams.input_channels, :, :])\n",
    "with torch.no_grad():\n",
    "    fake_imgs = model(z)\n",
    "\n",
    "# --- check statistics ---\n",
    "def print_stats(name, tensor):\n",
    "    print(f\"\\n{name} stats:\")\n",
    "    print(f\"  shape: {tuple(tensor.shape)}\")\n",
    "    print(f\"  global min: {tensor.min().item():.4f}\")\n",
    "    print(f\"  global max: {tensor.max().item():.4f}\")\n",
    "    print(f\"  mean: {tensor.mean().item():.4f}\")\n",
    "    print(f\"  std:  {tensor.std().item():.4f}\")\n",
    "    # per-channel stats (first few channels)\n",
    "    if tensor.size(1) > 1:\n",
    "        for c in range(min(3, tensor.size(1))):\n",
    "            print(f\"  channel {c}: min={tensor[:, c].min().item():.3f}, max={tensor[:, c].max().item():.3f}\")\n",
    "\n",
    "print_stats(\"REAL\", real_imgs)\n",
    "print_stats(\"FAKE\", fake_imgs)\n",
    "\n",
    "# --- visualize one sample ---\n",
    "def show_tensor_grid(tensor, title):\n",
    "    grid = make_grid(tensor[:4].detach().cpu(), nrow=4, normalize=True, value_range=(-1, 1))\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "show_tensor_grid(real_imgs, \"Real Images\")\n",
    "show_tensor_grid(fake_imgs, \"Fake Images\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperskin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
